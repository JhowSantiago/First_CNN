{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JhowSantiago/First_CNN/blob/main/Cats_and_Dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92QqBJ210_0K"
      },
      "outputs": [],
      "source": [
        "#Baixando uma base de dados compactada que possui imagens de gatos e cachorros\n",
        "!wget  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1NiBYd819fY"
      },
      "outputs": [],
      "source": [
        "#descompactando a pasta baixada\n",
        "!unzip cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZqZX7u92JPr"
      },
      "outputs": [],
      "source": [
        "#excluindo o arquivo .zip\n",
        "!rm -rf cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H39Zom52h1G"
      },
      "outputs": [],
      "source": [
        "#instalando a biblioteca do tensorflow\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XLzNv-X2sMt"
      },
      "outputs": [],
      "source": [
        "#biblioteca os auxilia em tarefas juntos ao sistema operacional\n",
        "#(vai ser utilizada para definir diretorios)\n",
        "import os\n",
        "\n",
        "#biblioteca para plotar graficos e imagens\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#biblioteca que vai ser usada para implementar o modelo\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhY_ZWAk3Pf5"
      },
      "outputs": [],
      "source": [
        "# caminho para o diretório principal do conjunto de dados\n",
        "#Ele usa a função os.getcwd() para obter o caminho do diretório atual\n",
        "#e os.path.join para adicionar o nome do diretório do conjunto de dados filtrado (que deve estar presente no diretório atual) ao caminho.\n",
        "dataset_dir = os.path.join(os.getcwd(), 'cats_and_dogs_filtered')\n",
        "\n",
        "# caminhos para os diretórios de treinamento e validação\n",
        "dataset_train_dir = os.path.join(dataset_dir, 'train')\n",
        "dataset_validation_dir = os.path.join(dataset_dir, 'validation')\n",
        "\n",
        "#iris_atena_dir = os.path.join(os.getcwd(), 'iris_atena')\n",
        "#iris_atena = os.path.join(iris_atena_dir, 'fotos')\n",
        "\n",
        "# contar o número de imagens de gatos e cachorros no conjunto de treinamento\n",
        "dataset_train_cats_len = len(os.listdir(os.path.join(dataset_train_dir, 'cats')))\n",
        "dataset_train_dogs_len = len(os.listdir(os.path.join(dataset_train_dir, 'dogs')))\n",
        "#iris_atena_len = len(os.listdir(os.path.join(iris_atena_dir,'fotos')))\n",
        "\n",
        "# contar o número de imagens de gatos e cachorros no conjunto de validação\n",
        "dataset_validation_cats_len = len(os.listdir(os.path.join(dataset_validation_dir, 'cats')))\n",
        "dataset_validation_dogs_len = len(os.listdir(os.path.join(dataset_validation_dir, 'dogs')))\n",
        "#iris_atena_len = len(os.listdir(os.path.join(iris_atena)))\n",
        "\n",
        "# exibir os resultados\n",
        "print('Train Cats: %s' % dataset_train_cats_len)\n",
        "print('Train Dogs: %s' % dataset_train_dogs_len)\n",
        "print('Validation Cats: %s' % dataset_validation_cats_len)\n",
        "print('Validation Dogs: %s' % dataset_validation_dogs_len)\n",
        "#print('iris_atena: %s' % iris_atena_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HJ8qqv96aEm"
      },
      "outputs": [],
      "source": [
        "# Define as dimensões da imagem que será usada no treinamento\n",
        "image_width = 160\n",
        "image_height = 160\n",
        "image_color_channel = 3 # RGB (vermelho, verde e azul)\n",
        "image_color_channel_size = 255 # tamanho do canal de cores\n",
        "image_size = (image_width, image_height) # tamanho da imagem\n",
        "image_shape = image_size + (image_color_channel,) # dimensão da imagem (altura, largura, canal)\n",
        "\n",
        "# Define as variáveis usadas para treinamento do modelo\n",
        "batch_size = 32 # quantidade de exemplos que serão extraidas e utilizados para o treinamento\n",
        "epochs = 1 # número de vezes que o modelo irá passar por todo o conjunto de dados\n",
        "learning_rate = 0.0001 # taxa de aprendizado\n",
        "\n",
        "# Define os nomes das classes\n",
        "class_names = ['cat', 'dog']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG0yUybH8PcS",
        "outputId": "f63686c0-a744-489f-ab2d-20ed69f95199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Cria um objeto dataset a partir dos dados de treinamento\n",
        "dataset_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_train_dir, # diretório que contém os dados de treinamento\n",
        "    image_size = image_size, # tamanho da imagem\n",
        "    batch_size = batch_size, # tamanho do batch\n",
        "    shuffle=True # embaralhar os dados ou não\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY9C-U0A9RiY",
        "outputId": "98f90b48-5975-4b46-8429-5e698ac85220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Cria um objeto dataset a partir dos dados de treinamento\n",
        "dataset_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_validation_dir, # diretório que contém os dados de treinamento\n",
        "    image_size = image_size, # tamanho da imagem\n",
        "    batch_size = batch_size, # tamanho do batch\n",
        "    shuffle=True # embaralhar os dados ou não\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtdBHqozAdTa"
      },
      "source": [
        "dataset_validation_cardinality é uma variável que armazena o número de exemplos no conjunto de validação.\n",
        "\n",
        "dataset_validation_batches é uma variável que calcula quantos exemplos farão parte do conjunto de teste.\n",
        "\n",
        "dataset_test é um subconjunto do conjunto de validação que é usado para avaliar a performance do modelo.\n",
        "\n",
        "dataset_validation é o subconjunto do conjunto de validação que é usado para treinar o modelo.\n",
        "\n",
        "tf.data.experimental.cardinality() é uma função do TensorFlow que calcula a cardinalidade (número de exemplos) de um conjunto de dados.\n",
        "\n",
        "A função take() é usada para selecionar os primeiros exemplos de um conjunto de dados.\n",
        "\n",
        "A função skip() é usada para pular os primeiros exemplos de um conjunto de dados.\n",
        "\n",
        "As linhas finais imprimem a cardinalidade do conjunto de validação e do conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBAKnquU-PxE",
        "outputId": "ba1ac3be-cb65-4b8d-c2fd-47fd7fe28c35"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Dataset Cardinality: 6\n",
            "Test Dataset Cardinality: 26\n"
          ]
        }
      ],
      "source": [
        "# Calcula o número de exemplos no conjunto de validação\n",
        "dataset_validation_cardinality = tf.data.experimental.cardinality(dataset_validation)\n",
        "\n",
        "# Divide o conjunto de validação em um conjunto de teste e outro de validação\n",
        "dataset_validation_batches = dataset_validation_cardinality // 5\n",
        "dataset_test = dataset_validation.skip(dataset_validation_batches)\n",
        "dataset_validation = dataset_validation.take(dataset_validation_batches)\n",
        "\n",
        "# Imprime a cardinalidade do conjunto de validação e do conjunto de teste\n",
        "print('Validation Dataset Cardinality: %d' % tf.data.experimental.cardinality(dataset_validation))\n",
        "print('Test Dataset Cardinality: %d'% tf.data.experimental.cardinality(dataset_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T0AViBjBl_J"
      },
      "source": [
        "plot_dataset() é uma função que plota exemplos de um conjunto de dados.\n",
        "\n",
        "A função recebe um parâmetro dataset, que é um objeto do tipo tf.data.Dataset.\n",
        "\n",
        "plt.gcf().clear() é uma função do matplotlib que limpa a figura atual.\n",
        "\n",
        "plt.figure(figsize=(15, 15)) é uma função do matplotlib que cria uma nova figura com o tamanho especificado.\n",
        "\n",
        "for features, labels in dataset.take(1): itera sobre o conjunto de dados, obtendo as primeiras features e labels.\n",
        "\n",
        "for i in range(9): itera sobre os 9 primeiros exemplos do conjunto de dados.\n",
        "\n",
        "plt.subplot(3, 3, i+1) cria um subplot na posição atual da iteração.\n",
        "\n",
        "plt.axis('off') desabilita a exibição dos eixos x e y no gráfico.\n",
        "\n",
        "plt.imshow(features[i].numpy().astype('uint8')) exibe a imagem do exemplo atual.\n",
        "\n",
        "plt.title(class_names[labels[i]]) exibe o título do exemplo atual, que é o nome da classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6BMRGGyA1dY"
      },
      "outputs": [],
      "source": [
        "def plot_dataset(dataset):\n",
        "    # Limpa a figura atual\n",
        "    plt.gcf().clear()\n",
        "    # Cria uma nova figura com tamanho 15x15\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    # Itera sobre o conjunto de dados, obtendo as primeiras features e labels\n",
        "    for features, labels in dataset.take(1):\n",
        "        # Itera sobre os 9 primeiros exemplos do conjunto de dados\n",
        "        for i in range(9):\n",
        "            # Cria um subplot na posição atual da iteração\n",
        "            plt.subplot(3, 3, i+1)\n",
        "            # Desabilita a exibição dos eixos x e y no gráfico\n",
        "            plt.axis('off')\n",
        "            # Exibe a imagem do exemplo atual\n",
        "            plt.imshow(features[i].numpy().astype('uint8'))\n",
        "            # Exibe o título do exemplo atual, que é o nome da classe\n",
        "            plt.title(class_names[labels[i]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUpBfFIMCC2K"
      },
      "outputs": [],
      "source": [
        "#chamando a funcao e passando o dataset como parametro\n",
        "plot_dataset(dataset_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "04ab6E9FCLg0"
      },
      "outputs": [],
      "source": [
        "#chamando a funcao e passando o dataset como parametro\n",
        "plot_dataset(dataset_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s9DtP7_4CN26"
      },
      "outputs": [],
      "source": [
        "#chamando a funcao e passando o dataset como parametro\n",
        "plot_dataset(dataset_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxO3Sovx1HhP"
      },
      "source": [
        "Neste trecho de código, é definida uma técnica para evitar o overfitting em modelos de rede neural. A técnica é chamada de aumento de dados (data augmentation) e é aplicada em imagens. O objeto data_augmentation é criado como uma sequência de camadas em um modelo sequencial (tf.keras.models.Sequential).\n",
        "\n",
        "As três camadas dentro do modelo sequencial são responsáveis por aplicar transformações aleatórias às imagens:\n",
        "\n",
        "tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'): Esta camada aplica o flip horizontal nas imagens, ou seja, as imagens são espelhadas horizontalmente.\n",
        "\n",
        "tf.keras.layers.experimental.preprocessing.RandomRotation(0.2): Esta camada aplica uma rotação aleatória nas imagens com um fator de rotação de 0.2, o que significa que as imagens podem ser giradas aleatoriamente em um ângulo máximo de 0.2 vezes a medida original.\n",
        "\n",
        "tf.keras.layers.experimental.preprocessing.RandomZoom(0.2): Esta camada aplica um zoom aleatório nas imagens com um fator de zoom de 0.2, o que significa que as imagens podem ser ampliadas ou reduzidas aleatoriamente em até 20%.\n",
        "\n",
        "Essas transformações são aplicadas durante o treinamento do modelo e ajudam a introduzir variações nas imagens de entrada, o que pode melhorar a generalização e reduzir o overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ehGENwG7z6nV"
      },
      "outputs": [],
      "source": [
        "# Técnica para evitar o overfitting\n",
        "\n",
        "data_augmentation = tf.keras.models.Sequential([\n",
        "     tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),  # Aplica o flip horizontal nas imagens\n",
        "     tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),  # Aplica rotação aleatória com um fator de 0.2\n",
        "     tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)  # Aplica zoom aleatório com um fator de 0.2\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewhyY9tDDIqF"
      },
      "source": [
        "O código define uma função chamada plot_dataset_data_augmentation que recebe um dataset como entrada. Essa função tem como objetivo plotar o resultado das features ao passar por camadas de data augmentation.\n",
        "\n",
        "Dentro da função, a figura atual é limpa e o tamanho da figura é definido. Em seguida, é feito um loop em que um batch de features é obtido do dataset. A primeira feature desse batch é armazenada em feature.\n",
        "\n",
        "Outro loop é iniciado para iterar 9 vezes, com o objetivo de plotar 9 imagens resultantes do data augmentation. Em cada iteração, a função data_augmentation é aplicada à feature usando tf.expand_dims para adicionar uma dimensão adicional à feature, necessária para a entrada no modelo. A imagem resultante do data augmentation é então plotada em um subplot correspondente usando plt.imshow.\n",
        "\n",
        "O resultado final é a exibição das 9 imagens resultantes do data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "znL7EGNx0i1n"
      },
      "outputs": [],
      "source": [
        "# Função para plotar o resultado das features ao passar pelas camadas de data_augmentation\n",
        "\n",
        "def plot_dataset_data_augmentation(dataset):\n",
        "  plt.gcf().clear()  # Limpa a figura atual\n",
        "  plt.figure(figsize=(15, 15))  # Define o tamanho da figura\n",
        "\n",
        "  for features, _ in dataset.take(1):  # Obtém um batch de features do dataset\n",
        "    feature = features[0]  # Obtém a primeira feature do batch\n",
        "\n",
        "  for i in range(9):  # Repete o processo 9 vezes para plotar 9 imagens resultantes do data augmentation\n",
        "    feature_data_augmentation = data_augmentation(tf.expand_dims(feature, 0))  # Aplica o data augmentation na feature\n",
        "\n",
        "    plt.subplot(3, 3, i+1)  # Cria um subplot 3x3\n",
        "    plt.axis('off')  # Desativa as marcações dos eixos\n",
        "\n",
        "    plt.imshow(feature_data_augmentation[0] / image_color_channel_size)  # Plota a imagem resultante do data augmentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exXRZyth26SI"
      },
      "outputs": [],
      "source": [
        "#executando a função plot_dataset_data_augmentation passando um dataset como parametro\n",
        "\n",
        "plot_dataset_data_augmentation(dataset_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOm-auwDDSW5"
      },
      "source": [
        "O código utiliza a técnica de Transfer Learning para criar um modelo de classificação de imagens.\n",
        "\n",
        "A variável model_transfer_learning é criada e recebe a instanciação de um modelo de transfer learning através da função tf.keras.applications.tr.\n",
        "\n",
        "Os parâmetros definidos são:\n",
        "\n",
        "input_shape: define a forma das imagens de entrada para o modelo.\n",
        "include_top: indica se a camada de classificação do modelo pré-treinado deve ser incluída.\n",
        "\n",
        "weights: especifica os pesos pré-treinados a serem utilizados. No caso, o valor 'imagenet' indica que serão utilizados os pesos do modelo pré-treinado ImageNet.\n",
        "\n",
        "Em seguida, model_transfer_learning.trainable é definido como False, o que significa que as camadas do modelo não serão treináveis durante o treinamento posterior.\n",
        "\n",
        "Por fim, model_transfer_learning.summary() é chamado para exibir um resumo do modelo transfer learning, mostrando a arquitetura das camadas e o número de parâmetros treináveis e não treináveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWV4ncdSCQWc"
      },
      "outputs": [],
      "source": [
        "# Técnica essencial para criação de um modelo para classificação de imagem usando Transfer Learning\n",
        "\n",
        "model_transfer_learning = tf.keras.applications.MobileNetV2(\n",
        "    input_shape = image_shape,  # Define a forma de entrada do modelo\n",
        "    include_top=False,  # Indica se deve incluir a camada de classificação no topo do modelo\n",
        "    weights='imagenet'  # Indica que devem ser utilizados os pesos pré-treinados do modelo 'imagenet'\n",
        ")\n",
        "\n",
        "model_transfer_learning.trainable = False  # Define que as camadas do modelo não serão treináveis\n",
        "\n",
        "model_transfer_learning.summary()  # Exibe o resumo do modelo transfer learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVPoghadFJ7u"
      },
      "source": [
        "\n",
        "O código está criando um modelo de rede neural sequencial com as seguintes camadas:\n",
        "\n",
        "Rescaling: camada de pré-processamento que normaliza os valores dos pixels das imagens, dividindo-os pelo valor máximo (255), para que fiquem na faixa entre 0 e 1.\n",
        "\n",
        "Conv2D: camada convolucional com 32 filtros de tamanho 3x3, função de ativação ReLU e preenchimento (padding) \"same\" para manter o tamanho da imagem de saída igual ao de entrada.\n",
        "\n",
        "MaxPooling2D: camada de pooling que reduz pela metade a resolução da imagem.\n",
        "\n",
        "Conv2D: camada convolucional com 64 filtros de tamanho 3x3, função de ativação ReLU e preenchimento \"same\".\n",
        "\n",
        "MaxPooling2D: camada de pooling que reduz pela metade a resolução da imagem.\n",
        "\n",
        "Conv2D: camada convolucional com 128 filtros de tamanho 3x3, função de ativação ReLU e preenchimento \"same\".\n",
        "\n",
        "MaxPooling2D: camada de pooling que reduz pela metade a resolução da imagem.\n",
        "\n",
        "Flatten: camada que transforma a saída da camada anterior (tensor tridimensional) em um vetor unidimensional.\n",
        "\n",
        "Dense: camada densa com 256 neurônios e função de ativação ReLU.\n",
        "\n",
        "Dense: camada densa com 1 neurônio e função de ativação sigmoid, que retorna uma probabilidade entre 0 e 1.\n",
        "\n",
        "Essas camadas formam uma rede neural convolucional (CNN) para classificação binária de imagens como cão ou gato.\n",
        "\n",
        "Utilizando o modelo novo melhorado\n",
        "\n",
        "data_augmentation: uma sequência de camadas que aplica transformações aleatórias às imagens, como flip horizontal, rotação e zoom.\n",
        "\n",
        "model_transfer_learning: uma camada que utiliza um modelo pré-treinado com transfer learning para extrair características das imagens.\n",
        "\n",
        "GlobalAveragePooling2D: camada de pooling global que calcula a média das características\n",
        "\n",
        "model.compile()\n",
        "O otimizador Adam é usado com uma taxa de aprendizagem especificada pela variável \"learning_rate\".\n",
        "\n",
        "A função de perda escolhida é a BinaryCrossentropy, que é apropriada para problemas de classificação binária.\n",
        "\n",
        "A métrica escolhida para avaliar o desempenho do modelo é a acurácia, que mede a proporção de predições corretas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_-A2YIWDIA8"
      },
      "outputs": [],
      "source": [
        "# cria uma sequência de camadas de rede\n",
        "model = tf.keras.models.Sequential([\n",
        "    # camada de normalização das intensidades dos pixels da imagem de entrada\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(\n",
        "        1. /(image_color_channel_size / 2),    # define o fator de escala\n",
        "        offset = -1,\n",
        "        input_shape = image_shape         # define o formato da imagem de entrada\n",
        "    ),\n",
        "\n",
        "    #--------------------------Antigo MODELO---------------------------#\n",
        "    # # camada de convolução 2D com 16 filtros, tamanho de filtro 3, função de ativação ReLU e preenchimento 'same'\n",
        "    # tf.keras.layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
        "\n",
        "    # # camada de pooling máx. 2D\n",
        "    # tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    # # camada de convolução 2D com 32 filtros, tamanho de filtro 3, função de ativação ReLU e preenchimento 'same'\n",
        "    # tf.keras.layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n",
        "\n",
        "    # # camada de pooling máx. 2D\n",
        "    # tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    # # camada de convolução 2D com 64 filtros, tamanho de filtro 3, função de ativação ReLU e preenchimento 'same'\n",
        "    # tf.keras.layers.Conv2D(128, 3, padding = 'same', activation = 'relu'),\n",
        "\n",
        "    # # camada de pooling máx. 2D\n",
        "    # tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    # # camada de achatamento dos dados em uma única dimensão\n",
        "    # tf.keras.layers.Flatten(),\n",
        "\n",
        "    # # camada densa com 128 neurônios e função de ativação ReLU\n",
        "    # tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "    #----------------------------------------------------------------#\n",
        "\n",
        "    #  Utiliza a técnica de aumento de dados (data augmentation)\n",
        "    data_augmentation,\n",
        "\n",
        "     # Utiliza um modelo pré-treinado com transfer learning\n",
        "    model_transfer_learning,\n",
        "\n",
        "     # Camada de average pooling global\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "    #camada que vai dropar alguns parametros para equilibrar o pedo da decisão entre todos os nós\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    # camada de saída com 1 neurônio e função de ativação sigmóide\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "# compila o modelo com um otimizador Adam, função de perda BinaryCrossentropy e métrica de acurácia\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "# exibe um resumo das camadas do modelo\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTA7irf7JkBH"
      },
      "source": [
        "\n",
        "Está sendo realizado o treinamento de uma rede neural.\n",
        "\n",
        "O método utilizado para o treinamento é o fit, que recebe os seguintes parâmetros:\n",
        "dataset_train: conjunto de dados de treinamento.\n",
        "validation_data: conjunto de dados de validação.\n",
        "\n",
        "epochs: número de épocas de treinamento.\n",
        "\n",
        "Durante o treinamento, a rede neural ajusta seus pesos para tentar minimizar a função de perda.\n",
        "\n",
        "Ao final de cada época, é avaliada a acurácia da rede neural nos conjuntos de treinamento e validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGiKpn6SG2jI"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    dataset_train,\n",
        "    validation_data = dataset_validation,\n",
        "    epochs = epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOS-qHW-07J3"
      },
      "source": [
        "O código possui uma função chamada plot_model() que plota a acurácia e a perda de treinamento e validação ao longo das épocas. Ele utiliza os valores de acurácia e perda armazenados no histórico (history) para isso.\n",
        "\n",
        "A função cria uma figura com dois subplots, um para a acurácia e outro para a perda. Em cada subplot, são plotadas as curvas de treinamento e validação correspondentes. Por fim, a função exibe o gráfico gerado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbOI4kZ1wt32"
      },
      "outputs": [],
      "source": [
        "# Analisando para ver se o modelo está bom ou ruim\n",
        "\n",
        "def plot_model():\n",
        "  accuracy = history.history['accuracy']  # Obtém os valores de acurácia do histórico\n",
        "  val_accuracy = history.history['val_accuracy']  # Obtém os valores de acurácia de validação do histórico\n",
        "\n",
        "  loss = history.history['loss']  # Obtém os valores de perda do histórico\n",
        "  val_loss = history.history['val_loss']  # Obtém os valores de perda de validação do histórico\n",
        "\n",
        "  epochs_range = range(epochs)  # Cria uma lista de números de épocas\n",
        "\n",
        "  plt.gcf().clear()  # Limpa a figura atual\n",
        "  plt.figure(figsize=(15, 8))  # Define o tamanho da figura\n",
        "\n",
        "  plt.subplot(1, 2, 1)  # Cria um subplot 1x2 (1 linha, 2 colunas), posição 1\n",
        "  plt.title('Training and Validation Accuracy')  # Define o título do gráfico\n",
        "  plt.plot(epochs_range, accuracy, label='Training Accuracy')  # Plota a acurácia de treinamento\n",
        "  plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')  # Plota a acurácia de validação\n",
        "  plt.legend(loc='lower right')  # Adiciona a legenda no canto inferior direito\n",
        "\n",
        "  plt.subplot(1, 2, 2)  # Cria um subplot 1x2, posição 2\n",
        "  plt.title('Training and Validation Loss')  # Define o título do gráfico\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')  # Plota a perda de treinamento\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')  # Plota a perda de validação\n",
        "  plt.legend(loc='lower right')  # Adiciona a legenda no canto inferior direito\n",
        "\n",
        "  plt.show()  # Mostra o gráfico\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7wHpHq6yrru"
      },
      "outputs": [],
      "source": [
        "#Executando a função acima para verificar se o modelo está se saindo bem\n",
        "plot_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPzZ7fa2J7xz"
      },
      "outputs": [],
      "source": [
        "# Vamos ver como a rede neural se comporta analisando um dataset que nunca viu\n",
        "def plot_dataset_predictions(dataset):\n",
        "\n",
        "    # Obtém as primeiras features e labels do conjunto de dados\n",
        "    features, labels = dataset.as_numpy_iterator().next()\n",
        "\n",
        "    # Realiza as previsões utilizando a rede neural\n",
        "    predictions = model.predict_on_batch(features).flatten()\n",
        "\n",
        "    # Transforma as previsões em valores binários (0 ou 1) de acordo com o limiar 0.5\n",
        "    predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "    # Imprime os labels e as previsões correspondentes\n",
        "    print('Labels:        %s' % labels)\n",
        "    print('Predictions:   %s' % predictions.numpy())\n",
        "\n",
        "    # Cria uma nova figura com tamanho 15x15\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.gcf().clear()\n",
        "\n",
        "    # Itera sobre os 9 primeiros exemplos do conjunto de dados\n",
        "    for i in range(9):\n",
        "        # Cria um subplot na posição atual da iteração\n",
        "        plt.subplot(3, 3, i+1)\n",
        "        # Desabilita a exibição dos eixos x e y no gráfico\n",
        "        plt.axis('off')\n",
        "        # Exibe a imagem do exemplo atual\n",
        "        plt.imshow(features[i].astype('uint8'))\n",
        "        # Exibe o título do exemplo atual, que é a classe prevista pela rede neural\n",
        "        plt.title(class_names[predictions[i]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ1LdfWftOGE"
      },
      "outputs": [],
      "source": [
        "print(len(dataset_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxHgsDwwL_HD"
      },
      "outputs": [],
      "source": [
        "#Inicializando um dataset que a CNN nunca viu para ver como se comporta nas\n",
        "#previsões\n",
        "plot_dataset_predictions(dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7ePnMJLwLW5"
      },
      "outputs": [],
      "source": [
        "#Salvando o modelo\n",
        "model.save('path/to/model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-ptNb__wRF9"
      },
      "outputs": [],
      "source": [
        "#para carregar o modelo\n",
        "\n",
        "model = tf.keras.models.load_model('path/to/model')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzpqIJCSQpcOfc7ekDhY0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}